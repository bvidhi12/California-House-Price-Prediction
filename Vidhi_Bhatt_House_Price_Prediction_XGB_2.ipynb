{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "A6HSgy1CepdO"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "600xmBFkpOXk",
        "outputId": "ded4abbe-da5f-4698-b79a-08f22baa9e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/v9/47dbywsd3kq7y4_mgpqb1kqm0000gn/T/ipykernel_22936/1710713689.py:6: DtypeWarning:\n",
            "\n",
            "Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1 = pd.read_csv('CRMLSSold202501_filled.csv')\n",
        "df2 = pd.read_csv('CRMLSSold202502_filled.csv')\n",
        "df3 = pd.read_csv('CRMLSSold202503_filled.csv')\n",
        "df4 = pd.read_csv('CRMLSSold202504_filled.csv')\n",
        "df5 = pd.read_csv('CRMLSSold202505_filled.csv')\n",
        "df6 = pd.read_csv('CRMLSSold202506_filled.csv')\n",
        "df7 = pd.read_csv('CRMLSSold202507_filled.csv')\n",
        "df8 = pd.read_csv('CRMLSSold202508_filled-2.csv')\n",
        "df9 = pd.read_csv('CRMLSSold202509.csv')\n",
        "\n",
        "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8,df9], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXodC2HWV50"
      },
      "source": [
        "**FILTERING FOR PROPERTY TYPE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxmp2_Gtp217",
        "outputId": "26364c7b-462b-47da-ce37-ed839402a7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(97987, 80)\n"
          ]
        }
      ],
      "source": [
        "df = df[\n",
        "    (df[\"PropertyType\"] == \"Residential\") &\n",
        "    (df[\"PropertySubType\"] == \"SingleFamilyResidence\")\n",
        "]\n",
        "\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqNoz2zLWbFx"
      },
      "source": [
        "**DROPPING OF COLUMNS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeWh8N-jqnSs",
        "outputId": "84ed2a1c-8368-47ce-82a0-dd64e5ef91b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['BuyerAgentAOR', 'ListAgentAOR', 'Flooring', 'ViewYN', 'WaterfrontYN',\n",
              "       'BasementYN', 'PoolPrivateYN', 'OriginalListPrice', 'ListingKey',\n",
              "       'ListAgentEmail', 'CloseDate', 'ClosePrice', 'ListAgentFirstName',\n",
              "       'ListAgentLastName', 'Latitude', 'Longitude', 'UnparsedAddress',\n",
              "       'PropertyType', 'LivingArea', 'ListPrice', 'DaysOnMarket',\n",
              "       'ListOfficeName', 'BuyerOfficeName', 'CoListOfficeName',\n",
              "       'ListAgentFullName', 'CoListAgentFirstName', 'CoListAgentLastName',\n",
              "       'BuyerAgentMlsId', 'BuyerAgentFirstName', 'BuyerAgentLastName',\n",
              "       'FireplacesTotal', 'AssociationFeeFrequency', 'AboveGradeFinishedArea',\n",
              "       'ListingKeyNumeric', 'MLSAreaMajor', 'TaxAnnualAmount',\n",
              "       'CountyOrParish', 'MlsStatus', 'ElementarySchool', 'AttachedGarageYN',\n",
              "       'ParkingTotal', 'BuilderName', 'PropertySubType', 'LotSizeAcres',\n",
              "       'SubdivisionName', 'BuyerOfficeAOR', 'YearBuilt', 'StreetNumberNumeric',\n",
              "       'ListingId', 'BathroomsTotalInteger', 'City', 'TaxYear',\n",
              "       'BuildingAreaTotal', 'BedroomsTotal', 'ContractStatusChangeDate',\n",
              "       'ElementarySchoolDistrict', 'CoBuyerAgentFirstName',\n",
              "       'PurchaseContractDate', 'ListingContractDate', 'BelowGradeFinishedArea',\n",
              "       'BusinessType', 'StateOrProvince', 'CoveredSpaces',\n",
              "       'MiddleOrJuniorSchool', 'FireplaceYN', 'Stories', 'HighSchool',\n",
              "       'Levels', 'LotSizeDimensions', 'LotSizeArea', 'MainLevelBedrooms',\n",
              "       'NewConstructionYN', 'GarageSpaces', 'HighSchoolDistrict', 'PostalCode',\n",
              "       'AssociationFee', 'LotSizeSquareFeet', 'MiddleOrJuniorSchoolDistrict',\n",
              "       'latfilled', 'lonfilled'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "B7eMz5odrXXo"
      },
      "outputs": [],
      "source": [
        "#columns to drop\n",
        "drop_cols = [\n",
        "    \"ListPrice\",\"OriginalListPrice\",\"DaysOnMarket\",\"ListingContractDate\",\n",
        "    \"ContractStatusChangeDate\",\"PurchaseContractDate\",\n",
        "    \"ListAgentAOR\",\"ListAgentEmail\",\"ListAgentFirstName\",\"ListAgentLastName\",\n",
        "    \"ListAgentFullName\",\"CoListAgentFirstName\",\"CoListAgentLastName\",\n",
        "    \"BuyerAgentAOR\",\"BuyerAgentMlsId\",\"BuyerAgentFirstName\",\"BuyerAgentLastName\",\n",
        "    \"CoBuyerAgentFirstName\",\"BuyerOfficeAOR\",\"ListOfficeName\",\"BuyerOfficeName\",\n",
        "    \"CoListOfficeName\",\"MlsStatus\",\"ListingKey\",\"ListingId\",\"ListingKeyNumeric\",\n",
        "    \"AssociationFeeFrequency\", \"MLSAreaMajor\", \"BusinessType\",\"latfilled\",\"lonfilled\"\n",
        "]\n",
        "df = df.drop(columns=[c for c in drop_cols if c in df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"ClosePrice\"] = df[\"ClosePrice\"].round(-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"City\"] = df[\"City\"].replace({\n",
        "    \"East Los Angeles\": \"Los Angeles\",\n",
        "    \"Lake Los Angeles\": \"Los Angeles\",\n",
        "    \"East San Diego\": \"San Diego\",\n",
        "    \"North Park (San Diego)\": \"San Diego\",\n",
        "    \"Ocean Beach (San Diego)\": \"San Diego\",\n",
        "    \"Rancho Bernardo (San Diego)\": \"San Diego\",\n",
        "    \"Pacific Beach (San Diego)\": \"San Diego\",\n",
        "    \"Big Bear\": \"Big Bear Lake\",\n",
        "    \"Big Bear City\": \"Big Bear Lake\",\n",
        "    \"Brentwood (CC)\": \"Brentwood\",\n",
        "    \"Carmel by the Sea\": \"Carmel\",\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[~df[\"City\"].isin([\"Outside Area (Outside Ca)\", \"Outside Area (Outside U.S.) Foreign Country\"])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TvnKvVHtl1o"
      },
      "source": [
        "**Evaluating Missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q4kkhOx7tIfw",
        "outputId": "9b6ae6ef-2897-425f-ce46-3ae0d005aed2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MainLevelBedrooms        0.394307\n",
              "Flooring                 0.354341\n",
              "AssociationFee           0.294442\n",
              "HighSchoolDistrict       0.268580\n",
              "Stories                  0.110775\n",
              "Levels                   0.076647\n",
              "GarageSpaces             0.039813\n",
              "LotSizeAcres             0.017626\n",
              "LotSizeSquareFeet        0.017626\n",
              "LotSizeArea              0.017534\n",
              "StreetNumberNumeric      0.001133\n",
              "UnparsedAddress          0.000939\n",
              "YearBuilt                0.000755\n",
              "City                     0.000714\n",
              "LivingArea               0.000592\n",
              "BathroomsTotalInteger    0.000194\n",
              "Longitude                0.000061\n",
              "Latitude                 0.000061\n",
              "PostalCode               0.000010\n",
              "ParkingTotal             0.000010\n",
              "PoolPrivateYN            0.000000\n",
              "CloseDate                0.000000\n",
              "ClosePrice               0.000000\n",
              "NewConstructionYN        0.000000\n",
              "PropertyType             0.000000\n",
              "AttachedGarageYN         0.000000\n",
              "ViewYN                   0.000000\n",
              "FireplaceYN              0.000000\n",
              "CountyOrParish           0.000000\n",
              "BedroomsTotal            0.000000\n",
              "PropertySubType          0.000000\n",
              "StateOrProvince          0.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking for missing values by column\n",
        "missing_percentage = df.isnull().mean().sort_values(ascending=False)\n",
        "missing_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SY2aNr-tyvc",
        "outputId": "874220cb-4067-4a55-8852-36217f29abe4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols_to_drop = missing_percentage[missing_percentage > 0.6].index.tolist()\n",
        "cols_to_drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "_ElhsRDfOR6z"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=cols_to_drop, errors = 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSufdmruWoV5"
      },
      "source": [
        "**NULL VALUE COUNT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V4hxl8Ul8jRH",
        "outputId": "e5055848-4662-4333-b19f-696d6f4ae5ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MainLevelBedrooms        38635\n",
              "Flooring                 34719\n",
              "AssociationFee           28850\n",
              "HighSchoolDistrict       26316\n",
              "Stories                  10854\n",
              "Levels                    7510\n",
              "GarageSpaces              3901\n",
              "LotSizeAcres              1727\n",
              "LotSizeSquareFeet         1727\n",
              "LotSizeArea               1718\n",
              "StreetNumberNumeric        111\n",
              "UnparsedAddress             92\n",
              "YearBuilt                   74\n",
              "City                        70\n",
              "LivingArea                  58\n",
              "BathroomsTotalInteger       19\n",
              "Longitude                    6\n",
              "Latitude                     6\n",
              "PostalCode                   1\n",
              "ParkingTotal                 1\n",
              "PoolPrivateYN                0\n",
              "CloseDate                    0\n",
              "ClosePrice                   0\n",
              "NewConstructionYN            0\n",
              "PropertyType                 0\n",
              "AttachedGarageYN             0\n",
              "ViewYN                       0\n",
              "FireplaceYN                  0\n",
              "CountyOrParish               0\n",
              "BedroomsTotal                0\n",
              "PropertySubType              0\n",
              "StateOrProvince              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxkcIfISW1GG"
      },
      "source": [
        "**DEALING W BOOLEAN NULL VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toXYWYjU9Qxo",
        "outputId": "6f25db60-a666-4f96-941e-be577b3f7360"
      },
      "outputs": [],
      "source": [
        "bool_cols = [\"ViewYN\", \"PoolPrivateYN\", \"AttachedGarageYN\",\n",
        "             \"FireplaceYN\",\"NewConstructionYN\"]\n",
        "\n",
        "df[bool_cols] = df[bool_cols].fillna(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Rexh5RW5SW"
      },
      "source": [
        "**SEPARATING THE NUM AND CATE COLUMNS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovTKZ7PVAMa0",
        "outputId": "aa6859f7-c3cc-425f-c3e5-e172de9cd3bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Latitude',\n",
              " 'Longitude',\n",
              " 'LivingArea',\n",
              " 'ParkingTotal',\n",
              " 'LotSizeAcres',\n",
              " 'YearBuilt',\n",
              " 'StreetNumberNumeric',\n",
              " 'BathroomsTotalInteger',\n",
              " 'BedroomsTotal',\n",
              " 'Stories',\n",
              " 'LotSizeArea',\n",
              " 'MainLevelBedrooms',\n",
              " 'GarageSpaces',\n",
              " 'AssociationFee',\n",
              " 'LotSizeSquareFeet']"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numerical_cols = df.select_dtypes(include=['int64','float64']).columns.tolist() \n",
        "num_cols = [col for col in numerical_cols if col != 'ClosePrice']\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET99YiVH5uzV"
      },
      "source": [
        "**SEPARATING TRAIN AND TEST USING CLOSE DATE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "oWhMgyYg5t_b"
      },
      "outputs": [],
      "source": [
        "df[\"CloseDate\"] = pd.to_datetime(df[\"CloseDate\"], errors=\"coerce\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29NFPFRI7QyT",
        "outputId": "b99631d6-028e-4b61-8d81-bde2ed1457ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(df[\"CloseDate\"].dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "xyCSi_gW6yfO"
      },
      "outputs": [],
      "source": [
        "mask = (df[\"CloseDate\"].dt.year == 2025) & (df[\"CloseDate\"].dt.month == 9)\n",
        "\n",
        "test_df = df[mask].copy()\n",
        "train_df = df[~mask].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDCD9BG3XKPi"
      },
      "source": [
        "**IMPUTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "6nsceMYsVsSF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "cols = [\"LivingArea\",\"AssociationFee\"]\n",
        "\n",
        "scaler = RobustScaler()\n",
        "imp = KNNImputer(n_neighbors=7, weights=\"distance\")\n",
        "\n",
        "# fit on train\n",
        "X_train = scaler.fit_transform(train_df[cols])\n",
        "X_train_imp = imp.fit_transform(X_train)\n",
        "train_df[cols] = scaler.inverse_transform(X_train_imp)\n",
        "\n",
        "# transform test with same fit\n",
        "X_test = scaler.transform(test_df[cols])\n",
        "X_test_imp = imp.transform(X_test)\n",
        "test_df[cols] = scaler.inverse_transform(X_test_imp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "RayJMMdFcM20"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "train_df[\"Stories\"] = imputer.fit_transform(train_df[[\"Stories\"]]).ravel()\n",
        "\n",
        "test_df[\"Stories\"] = imputer.transform(test_df[[\"Stories\"]]).ravel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W3KNCobdN4O",
        "outputId": "68784810-bae0-4721-a19f-94328de1254d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/v9/47dbywsd3kq7y4_mgpqb1kqm0000gn/T/ipykernel_22936/2410216566.py:25: FutureWarning:\n",
            "\n",
            "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Train ---\n",
        "s_train = pd.to_numeric(train_df[\"Stories\"], errors=\"coerce\")\n",
        "fill_train = s_train.map({1: \"One\", 2: \"Two\"})\n",
        "\n",
        "miss_train = train_df[\"Levels\"].isna()\n",
        "train_df.loc[miss_train, \"Levels\"] = fill_train[miss_train]\n",
        "\n",
        "# fallback to mode from train only\n",
        "if train_df[\"Levels\"].isna().any():\n",
        "    mode_val = train_df[\"Levels\"].dropna().mode().iloc[0]\n",
        "    train_df[\"Levels\"].fillna(mode_val, inplace=True)\n",
        "else:\n",
        "    mode_val = train_df[\"Levels\"].dropna().mode().iloc[0]\n",
        "\n",
        "train_df[\"Levels\"] = train_df[\"Levels\"].astype(\"category\")\n",
        "\n",
        "# --- Test ---\n",
        "s_test = pd.to_numeric(test_df[\"Stories\"], errors=\"coerce\")\n",
        "fill_test = s_test.map({1: \"One\", 2: \"Two\"})\n",
        "\n",
        "miss_test = test_df[\"Levels\"].isna()\n",
        "test_df.loc[miss_test, \"Levels\"] = fill_test[miss_test]\n",
        "\n",
        "# use mode derived from train_df\n",
        "test_df[\"Levels\"].fillna(mode_val, inplace=True)\n",
        "test_df[\"Levels\"] = test_df[\"Levels\"].astype(\"category\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "Mf0CzBLvE21k"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_cols = [\"YearBuilt\", \"BathroomsTotalInteger\", \"BedroomsTotal\",\n",
        "            \"ParkingTotal\", \"MainLevelBedrooms\", \"GarageSpaces\"]\n",
        "\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "# fit only on train\n",
        "train_df[num_cols] = num_imputer.fit_transform(train_df[num_cols])\n",
        "test_df[num_cols]  = num_imputer.transform(test_df[num_cols])\n",
        "\n",
        "# round and cast\n",
        "for c in num_cols:\n",
        "    train_df[c] = train_df[c].round().astype(\"Int64\")\n",
        "    test_df[c]  = test_df[c].round().astype(\"Int64\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "8_CyoJkJjAjC"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.dropna(subset=[\"StreetNumberNumeric\",\"Latitude\",\"Longitude\",\"UnparsedAddress\",\"City\",\"PostalCode\"]).copy()\n",
        "test_df = test_df.dropna(subset=[\"StreetNumberNumeric\",\"Latitude\",\"Longitude\",\"UnparsedAddress\",\"City\",\"PostalCode\"]).copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "knhm-ZHplefa"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# materials = [\"Bamboo\",\"Brick\",\"Carpet\",\"Concrete\",\"Laminate\",\"Stone\",\"Tile\",\"Vinyl\",\"Wood\"]\n",
        "\n",
        "# def parse_flooring(s):\n",
        "#     if pd.isna(s):\n",
        "#         return []\n",
        "#     toks = [t.strip().title() for t in str(s).split(\",\") if t.strip()]\n",
        "#     bad = {\"Seeremarks\",\"See Remarks\",\"See-Remarks\"}\n",
        "#     return [t for t in toks if t not in bad]\n",
        "\n",
        "# # --- train ---\n",
        "# lists_train = train_df[\"Flooring\"].map(parse_flooring)\n",
        "# mlb = MultiLabelBinarizer(classes=materials)\n",
        "# X_train = mlb.fit_transform(lists_train)\n",
        "# train_df[materials] = pd.DataFrame(X_train, index=train_df.index, columns=materials).astype(\"int8\")\n",
        "\n",
        "# # --- test ---\n",
        "# lists_test = test_df[\"Flooring\"].map(parse_flooring)\n",
        "# X_test = mlb.transform(lists_test)\n",
        "# test_df[materials] = pd.DataFrame(X_test, index=test_df.index, columns=materials).astype(\"int8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 0) Clean PostalCode\n",
        "for d in (train_df, test_df):\n",
        "    d['PostalCode'] = d['PostalCode'].astype(str).str.strip().str.upper().replace({'': np.nan})\n",
        "\n",
        "# 1) PostalCode → median target (TRAIN ONLY)\n",
        "pc_price = (\n",
        "    train_df.loc[train_df['PostalCode'].notna(), ['PostalCode', 'ClosePrice']]\n",
        "    .groupby('PostalCode', as_index=False)['ClosePrice'].median()\n",
        "    .rename(columns={'ClosePrice':'PC_MedianPrice'})\n",
        ")\n",
        "\n",
        "# 2) Bin medians into k quantile clusters (no lat/lon)\n",
        "k = 10\n",
        "# if too few unique postals, reduce k\n",
        "k = min(k, pc_price['PC_MedianPrice'].nunique())\n",
        "labels = pd.qcut(pc_price['PC_MedianPrice'], q=k, labels=False, duplicates='drop')\n",
        "pc_price['GeoCluster'] = labels.astype(int)\n",
        "\n",
        "# 3) Map PostalCode → cluster\n",
        "PC2CLUSTER = dict(zip(pc_price['PostalCode'], pc_price['GeoCluster']))\n",
        "\n",
        "def assign_cluster_postal(df, mapping, unknown_label=-1):\n",
        "    lab = df['PostalCode'].map(mapping)\n",
        "    return lab.fillna(unknown_label).astype(int)\n",
        "\n",
        "train_df['GeoCluster'] = assign_cluster_postal(train_df, PC2CLUSTER)\n",
        "test_df['GeoCluster']  = assign_cluster_postal(test_df,  PC2CLUSTER)\n",
        "\n",
        "# 4) One-hot encode and align\n",
        "train_df = pd.get_dummies(train_df, columns=['GeoCluster'], prefix='GC', drop_first=True)\n",
        "test_df  = pd.get_dummies(test_df,  columns=['GeoCluster'], prefix='GC', drop_first=True)\n",
        "test_df  = test_df.reindex(columns=train_df.columns, fill_value=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = ['Flooring','LotSizeSquareFeet','LotSizeArea','StreetNumberNumeric','HighSchoolDistrict','Latitude','Longitude','PostalCode']\n",
        "train_df.drop(columns=cols, inplace=True, errors='ignore')\n",
        "test_df.drop(columns=cols, inplace=True, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['Age'] = 2025 - train_df['YearBuilt']\n",
        "test_df['Age']  = 2025 - test_df['YearBuilt']\n",
        "train_df.drop(columns=['YearBuilt'], inplace=True, errors='ignore')\n",
        "test_df.drop(columns=['YearBuilt'], inplace=True, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['ViewYN', 'PoolPrivateYN', 'CloseDate', 'ClosePrice', 'UnparsedAddress',\n",
              "       'PropertyType', 'LivingArea', 'CountyOrParish', 'AttachedGarageYN',\n",
              "       'ParkingTotal', 'PropertySubType', 'LotSizeAcres',\n",
              "       'BathroomsTotalInteger', 'City', 'BedroomsTotal', 'StateOrProvince',\n",
              "       'FireplaceYN', 'Stories', 'Levels', 'MainLevelBedrooms',\n",
              "       'NewConstructionYN', 'GarageSpaces', 'AssociationFee', 'GC_1', 'GC_2',\n",
              "       'GC_3', 'GC_4', 'GC_5', 'GC_6', 'GC_7', 'GC_8', 'GC_9', 'Age'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 feature        VIF\n",
            "4          BedroomsTotal  23.171031\n",
            "3  BathroomsTotalInteger  22.057533\n",
            "0             LivingArea  16.137503\n",
            "5                Stories   9.597112\n",
            "9                    Age   3.434247\n",
            "6      MainLevelBedrooms   2.868557\n",
            "7           GarageSpaces   1.451632\n",
            "8         AssociationFee   1.256380\n",
            "1           ParkingTotal   1.004705\n",
            "2           LotSizeAcres   1.000341\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "target = 'ClosePrice'\n",
        "\n",
        "# 1) numeric-only, exclude target\n",
        "num_df = train_df.select_dtypes(include=['number']).drop(columns=[target], errors='ignore')\n",
        "\n",
        "# 2) force float dtype (handles Int64/booleans/nullable)\n",
        "num_df = num_df.apply(pd.to_numeric, errors='coerce').astype('float64')\n",
        "\n",
        "# 3) drop non-finite rows\n",
        "num_df = num_df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how='any')\n",
        "\n",
        "# 4) drop zero-variance columns (VIF undefined)\n",
        "vt = VarianceThreshold(threshold=0.0)\n",
        "_ = vt.fit(num_df)\n",
        "num_df = num_df.loc[:, vt.get_feature_names_out(num_df.columns)]\n",
        "\n",
        "# 5) compute VIF\n",
        "X = num_df.values  # pure float64\n",
        "vif = pd.DataFrame({\n",
        "    \"feature\": num_df.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
        "}).sort_values(\"VIF\", ascending=False)\n",
        "\n",
        "print(vif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "keep_cols = [\n",
        "    'LivingArea', 'ParkingTotal', 'LotSizeAcres', 'BathroomsTotalInteger', 'ClosePrice',\n",
        "    'City', 'BedroomsTotal','Stories',\n",
        "    'MainLevelBedrooms', 'GarageSpaces','Age'\n",
        "] + [c for c in train_df.columns if c.startswith('GC_')]\n",
        "\n",
        "train_df = train_df[keep_cols].copy()\n",
        "test_df  = test_df[keep_cols].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R²: 0.8623333434877336\n",
            "MAPE: 0.1565623818969001\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Trim outliers (0.5% from top and bottom) ---\n",
        "def trim_quantile(df, target='ClosePrice', q=0.005):\n",
        "    lo = df[target].quantile(q)\n",
        "    hi = df[target].quantile(1 - q)\n",
        "    return df[(df[target] >= lo) & (df[target] <= hi)].copy()\n",
        "\n",
        "train_t = trim_quantile(train_df, q=0.005)\n",
        "test_t  = trim_quantile(test_df,  q=0.005)\n",
        "\n",
        "# --- 2. Split features and target ---\n",
        "target = 'ClosePrice'\n",
        "X_train = train_t.drop(columns=[target, 'CloseDate', 'UnparsedAddress'], errors='ignore')\n",
        "y_train = train_t[target]\n",
        "X_test  = test_t.drop(columns=[target, 'CloseDate', 'UnparsedAddress'], errors='ignore')\n",
        "y_test  = test_t[target]\n",
        "\n",
        "# --- 3. One-hot encode categorical features ---\n",
        "cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
        "X_train = pd.get_dummies(X_train, columns=cat_cols, drop_first=True)\n",
        "X_test  = pd.get_dummies(X_test,  columns=cat_cols, drop_first=True)\n",
        "X_test  = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "\n",
        "# --- 4. Model training ---\n",
        "model = XGBRegressor(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=8,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    tree_method='hist',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# y_train_log = np.log1p(y_train)\n",
        "# model.fit(X_train, y_train_log)\n",
        "# y_pred = np.expm1(model.predict(X_test))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- 5. Evaluation ---\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"R²:\", metrics.r2_score(y_test, y_pred))\n",
        "print(\"MAPE:\", mean_absolute_percentage_error(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median Absolute Percentage Error (MdAPE): 10.97%\n"
          ]
        }
      ],
      "source": [
        "def calculate_mdape(y_true, y_pred):\n",
        "    \"\"\"Calculates the Median Absolute Percentage Error (MdAPE).\"\"\"\n",
        "    # Exclude cases where the actual value is zero to avoid division by zero\n",
        "    non_zero_indices = y_true != 0\n",
        "    y_true_filtered = y_true[non_zero_indices]\n",
        "    y_pred_filtered = y_pred[non_zero_indices]\n",
        "\n",
        "    # Calculate Absolute Percentage Error (APE)\n",
        "    ape = np.abs((y_true_filtered - y_pred_filtered) / y_true_filtered)\n",
        "\n",
        "    # Return the median of the APE\n",
        "    return np.median(ape) * 100 # Return as a percentage\n",
        "\n",
        "# Calculate and print the MdAPE\n",
        "mdape_score = calculate_mdape(y_test, y_pred)\n",
        "print(f\"Median Absolute Percentage Error (MdAPE): {mdape_score:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "FEATURE_COLS = list(X_train.columns)\n",
        "\n",
        "with open(\"model_columns.json\", \"w\") as f:\n",
        "    json.dump({\"columns\": FEATURE_COLS}, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "# Save model\n",
        "with open(\"xgb_houseprice.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Save feature columns\n",
        "with open(\"model_columns.json\", \"w\") as f:\n",
        "    json.dump({\"columns\": list(X_train.columns)}, f)\n",
        "\n",
        "# Save postal code → cluster map\n",
        "with open(\"pc2cluster.pkl\", \"wb\") as f:\n",
        "    pickle.dump(PC2CLUSTER, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "# after you compute y_pred on test_t in training\n",
        "eval_df = test_t[['City']].copy()\n",
        "eval_df['Actual'] = y_test.values\n",
        "eval_df['Predicted'] = y_pred\n",
        "pickle.dump(eval_df, open(\"eval_df.pkl\",\"wb\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
